{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70e0c5-d242-4242-90f3-f63094fa91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df['normalized_value'] = scaler.fit_transform(df['value'].values.reshape(-1, 1))\n",
    "\n",
    "# Split into training and test sets (e.g., 80% train, 20% test)\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_data, test_data = df.iloc[:train_size], df.iloc[train_size:]\n",
    "\n",
    "# Optionally, perform cross-validation on the training set\n",
    "\n",
    "# Further processing as needed for model input\n",
    "\n",
    "# Example output\n",
    "print(\"Training set shape:\", train_data.shape)\n",
    "print(\"Test set shape:\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv\"\n",
    "data = pd.read_csv(url, parse_dates=['Date'], index_col='Date')\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Define function to create dataset with input and output sequences\n",
    "def create_dataset(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps), 0])\n",
    "        y.append(data[i + time_steps, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Set time steps and split into train and test sets\n",
    "time_steps = 30\n",
    "X, y = create_dataset(data_scaled, time_steps)\n",
    "X_train, X_test = X[:int(X.shape[0]*0.8)], X[int(X.shape[0]*0.8):]\n",
    "y_train, y_test = y[:int(y.shape[0]*0.8)], y[int(y.shape[0]*0.8):]\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Plot training loss and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Make predictions\n",
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Invert predictions to original scale\n",
    "train_predictions = scaler.inverse_transform(train_predictions)\n",
    "y_train = scaler.inverse_transform([y_train])\n",
    "test_predictions = scaler.inverse_transform(test_predictions)\n",
    "y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "# Calculate RMSE\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train[0], train_predictions[:,0]))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test[0], test_predictions[:,0]))\n",
    "print('Train RMSE:', train_rmse)\n",
    "print('Test RMSE:', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d9bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv\"\n",
    "data = pd.read_csv(url, parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Preprocessing\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Splitting into training and test sets\n",
    "train_size = int(len(data_scaled) * 0.8)  # 80% for training\n",
    "test_size = len(data_scaled) - train_size\n",
    "train, test = data_scaled[0:train_size,:], data_scaled[train_size:len(data_scaled),:]\n",
    "\n",
    "print(\"Training set size:\", len(train))\n",
    "print(\"Test set size:\", len(test))\n",
    "\n",
    "# Visualize the original and normalized data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data.index, data['Temp'], label='Original Data')\n",
    "plt.title('Daily Minimum Temperatures in Melbourne')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (Â°C)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78554d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f753c45-9152-4233-bd35-10ac08c867e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_lstm_model(input_shape, lstm_units=(50, 50), dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the first LSTM layer\n",
    "    model.add(LSTM(units=lstm_units[0], input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    # Add additional LSTM layers if specified\n",
    "    if len(lstm_units) > 1:\n",
    "        for units in lstm_units[1:]:\n",
    "            model.add(LSTM(units=units, return_sequences=True))\n",
    "            model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    # Add the output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define input shape (time steps, features)\n",
    "X=df.iloc[:,:-1].values\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Define LSTM units and dropout rate\n",
    "lstm_units = (64, 64)  # Two LSTM layers with 64 units each\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# Create the LSTM model\n",
    "model = create_lstm_model(input_shape, lstm_units, dropout_rate)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad859b-dfd4-422f-a0a1-e2a5d5a524ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs\n",
    "epochs = 50\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    shuffle=True)\n",
    "\n",
    "# Plot training/validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16345788-bb52-4b8b-bf6b-e8cafb0cbfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs\n",
    "epochs = 50\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    shuffle=True)\n",
    "\n",
    "# Plot training/validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c32c2-e14b-4185-b174-0888e8aee091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Invert predictions and actual values to original scale\n",
    "test_predictions = scaler.inverse_transform(test_predictions)\n",
    "y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test[0], test_predictions[:, 0])\n",
    "rmse = np.sqrt(mean_squared_error(y_test[0], test_predictions[:, 0]))\n",
    "print('Mean Absolute Error (MAE):', mae)\n",
    "print('Root Mean Squared Error (RMSE):', rmse)\n",
    "\n",
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test[0], label='Actual')\n",
    "plt.plot(test_predictions[:, 0], label='Predicted')\n",
    "plt.title('Test Set Predictions vs Actual Values')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Temperature')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
